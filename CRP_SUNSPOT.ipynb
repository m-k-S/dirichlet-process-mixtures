{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CRP_SUNSPOT",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsNfrvA4LxFC",
        "colab_type": "code",
        "outputId": "292eebe5-4554-4dad-e220-5123b3db8c98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "import torch\n",
        "!pip install pyro-ppl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pyro.distributions as dist\n",
        "import pyro\n",
        "from torch.autograd import Variable\n",
        "from pyro.infer.autoguide import AutoDiagonalNormal, AutoDelta\n",
        "from pyro.optim import Adam\n",
        "from pyro.infer import SVI, TraceEnum_ELBO, TracePredictive, EmpiricalMarginal\n",
        "from torch.distributions import constraints\n",
        "from pyro import poutine"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyro-ppl in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (0.1.1)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (4.36.1)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.17.3)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.3.0+cu100)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (3.1.0)\n",
            "Requirement already satisfied: graphviz>=0.8 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (0.10.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbP3G1YYL22Y",
        "colab_type": "code",
        "outputId": "1de6c0bc-219e-4df0-8456-e4b74a8116ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive\n",
        "%cd My\\ Drive\n",
        "%cd Colab\\ Notebooks\n",
        "\n",
        "df = pd.read_csv('sunspot.csv', sep=';', names=['time', 'sunspot.year'], usecols=[0, 1])\n",
        "print (df.head())\n",
        "\n",
        "plt.hist(df['sunspot.year'].values, bins=40)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n",
            "/gdrive/My Drive\n",
            "/gdrive/My Drive/Colab Notebooks\n",
            "     time  sunspot.year\n",
            "0  1700.5           8.3\n",
            "1  1701.5          18.3\n",
            "2  1702.5          26.7\n",
            "3  1703.5          38.3\n",
            "4  1704.5          60.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([16., 25., 25., 21., 10., 16., 14.,  8., 16., 13.,  9., 16.,  8.,\n",
              "         7., 10., 14.,  9.,  6.,  7.,  8.,  7.,  6.,  5.,  1.,  5.,  6.,\n",
              "         2.,  5.,  5.,  3.,  3.,  3.,  4.,  2.,  1.,  0.,  0.,  0.,  2.,\n",
              "         1.]),\n",
              " array([  0.    ,   6.7325,  13.465 ,  20.1975,  26.93  ,  33.6625,\n",
              "         40.395 ,  47.1275,  53.86  ,  60.5925,  67.325 ,  74.0575,\n",
              "         80.79  ,  87.5225,  94.255 , 100.9875, 107.72  , 114.4525,\n",
              "        121.185 , 127.9175, 134.65  , 141.3825, 148.115 , 154.8475,\n",
              "        161.58  , 168.3125, 175.045 , 181.7775, 188.51  , 195.2425,\n",
              "        201.975 , 208.7075, 215.44  , 222.1725, 228.905 , 235.6375,\n",
              "        242.37  , 249.1025, 255.835 , 262.5675, 269.3   ]),\n",
              " <a list of 40 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ75zZciMMqi",
        "colab_type": "code",
        "outputId": "e63c21fb-aaaf-4296-87ac-186cbe2e0db5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import time\n",
        "\n",
        "N = df.shape[0]\n",
        "\n",
        "data = torch.tensor(df['sunspot.year'].values, dtype=torch.float32)\n",
        "def crp_model(data):\n",
        "    alpha0 = pyro.sample('alpha', dist.Gamma(2, 4))\n",
        "    # alpha0 = 2.\n",
        "    cluster_rates = {}  # sample this lazily\n",
        "    crp_counts = []  # build this incrementally\n",
        "    for i in range(len(data)):\n",
        "        # sample from a CRP\n",
        "        weights = torch.tensor(crp_counts + [alpha0], dtype=torch.float32) \n",
        "        weights /= weights.sum()\n",
        "        crp_weights = pyro.param(\"weights_{}\".format(i), Variable(weights), constraint=constraints.positive)\n",
        "        # print (crp_weights)\n",
        "\n",
        "        zi = pyro.sample(\"z_{}\".format(i), dist.Categorical(crp_weights))\n",
        "        zi = zi.item() \n",
        "\n",
        "        if zi >= len(crp_counts):\n",
        "            crp_counts.append(1)  # sit at a new table\n",
        "        else:\n",
        "            crp_counts[zi] += 1  # sit at an existing table\n",
        "\n",
        "\n",
        "        # lazily sample cluster mean\n",
        "        if zi not in cluster_rates.keys():\n",
        "            cluster_rates[zi] = pyro.sample(\"lambda_{}\".format(zi), dist.Uniform(0, 200))\n",
        "        lambda_i = cluster_rates[zi]\n",
        "        pyro.sample(\"obs_{}\".format(i), dist.Poisson(lambda_i), obs=data[i])\n",
        "\n",
        "# guide = AutoDiagonalNormal(crp_model)\n",
        "guide = AutoDelta(poutine.block(crp_model, hide=['z_{}'.format(i) for i in range(len(data))]))\n",
        "optim = Adam({\"lr\": 0.05})\n",
        "svi = SVI(crp_model, guide, optim, loss=TraceEnum_ELBO(), num_samples=1000)\n",
        "\n",
        "def train(num_iterations):\n",
        "    pyro.clear_param_store()\n",
        "    for j in range(num_iterations):\n",
        "        loss = svi.step(data)\n",
        "        if j % 500 == 0:\n",
        "            print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / len(data)))\n",
        "\n",
        "train(1000)\n",
        "\n",
        "for name, value in pyro.get_param_store().items():\n",
        "    print(name, pyro.param(name))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[iteration 0001] loss: 29.1756\n",
            "[iteration 0501] loss: 27.5145\n",
            "weights_0 tensor([1.], grad_fn=<AddBackward0>)\n",
            "weights_1 tensor([2.7198, 0.0757], grad_fn=<AddBackward0>)\n",
            "weights_2 tensor([0.2665, 0.5278], grad_fn=<AddBackward0>)\n",
            "weights_3 tensor([3.8994, 0.0270], grad_fn=<AddBackward0>)\n",
            "weights_4 tensor([4.3224, 0.0194], grad_fn=<AddBackward0>)\n",
            "weights_5 tensor([1.3194e+01, 5.2843e-03], grad_fn=<AddBackward0>)\n",
            "weights_6 tensor([3.1031e+01, 1.9202e-03], grad_fn=<AddBackward0>)\n",
            "weights_7 tensor([1.0178, 0.0511], grad_fn=<AddBackward0>)\n",
            "weights_8 tensor([0.0498, 0.9264], grad_fn=<AddBackward0>)\n",
            "weights_9 tensor([3.1468e+01, 1.3176e-03], grad_fn=<AddBackward0>)\n",
            "weights_10 tensor([3.1558e+01, 1.1928e-03], grad_fn=<AddBackward0>)\n",
            "weights_11 tensor([1.1065, 0.0312], grad_fn=<AddBackward0>)\n",
            "weights_12 tensor([4.5458, 0.0070], grad_fn=<AddBackward0>)\n",
            "weights_13 tensor([3.1746e+01, 9.2885e-04], grad_fn=<AddBackward0>)\n",
            "weights_14 tensor([3.4497, 0.0080], grad_fn=<AddBackward0>)\n",
            "weights_15 tensor([3.1831e+01, 8.0942e-04], grad_fn=<AddBackward0>)\n",
            "weights_16 tensor([4.2930, 0.0056], grad_fn=<AddBackward0>)\n",
            "weights_17 tensor([8.3527e+00, 2.7388e-03], grad_fn=<AddBackward0>)\n",
            "weights_18 tensor([3.1922e+01, 6.7854e-04], grad_fn=<AddBackward0>)\n",
            "weights_19 tensor([3.1948e+01, 6.4384e-04], grad_fn=<AddBackward0>)\n",
            "weights_20 tensor([3.1969e+01, 6.1251e-04], grad_fn=<AddBackward0>)\n",
            "weights_21 tensor([3.1988e+01, 5.8409e-04], grad_fn=<AddBackward0>)\n",
            "weights_22 tensor([3.2007e+01, 5.5819e-04], grad_fn=<AddBackward0>)\n",
            "weights_23 tensor([5.4054e+00, 3.1666e-03], grad_fn=<AddBackward0>)\n",
            "weights_24 tensor([3.2036e+01, 5.1272e-04], grad_fn=<AddBackward0>)\n",
            "weights_25 tensor([3.2053e+01, 4.9267e-04], grad_fn=<AddBackward0>)\n",
            "weights_26 tensor([3.1254e+01, 1.1470e-03, 4.6771e-04], grad_fn=<AddBackward0>)\n",
            "weights_27 tensor([8.6454e+00, 6.9965e-04, 1.7210e-03], grad_fn=<AddBackward0>)\n",
            "weights_28 tensor([3.4107e+00, 7.1297e-03, 4.4844e-04], grad_fn=<AddBackward0>)\n",
            "weights_29 tensor([3.1372e+01, 1.0320e-03, 4.2084e-04], grad_fn=<AddBackward0>)\n",
            "weights_30 tensor([6.4991e-01, 4.2106e-02, 4.5529e-04], grad_fn=<AddBackward0>)\n",
            "weights_31 tensor([3.1437e+01, 9.6738e-04, 3.9448e-04], grad_fn=<AddBackward0>)\n",
            "weights_32 tensor([7.8404e-01, 4.1682e-02, 2.3160e-05], grad_fn=<AddBackward0>)\n",
            "weights_33 tensor([5.1901e+00, 5.1480e-03, 1.3075e-03], grad_fn=<AddBackward0>)\n",
            "weights_34 tensor([4.2755e+00, 7.5165e-03, 6.6522e-05], grad_fn=<AddBackward0>)\n",
            "weights_35 tensor([9.0419e+00, 3.2796e-03, 1.2660e-04], grad_fn=<AddBackward0>)\n",
            "weights_36 tensor([3.1568e+01, 8.3637e-04, 3.4106e-04], grad_fn=<AddBackward0>)\n",
            "weights_37 tensor([5.1369e+00, 5.7376e-03, 8.0179e-05], grad_fn=<AddBackward0>)\n",
            "weights_38 tensor([5.2057e-01, 5.3227e-02, 2.7004e-05], grad_fn=<AddBackward0>)\n",
            "weights_39 tensor([3.1632e+01, 7.7353e-04, 3.1543e-04], grad_fn=<AddBackward0>)\n",
            "weights_40 tensor([1.6969e+00, 6.3812e-05, 8.0610e-03], grad_fn=<AddBackward0>)\n",
            "weights_41 tensor([3.1671e+01, 7.3663e-04, 3.0038e-04], grad_fn=<AddBackward0>)\n",
            "weights_42 tensor([1.9451e+00, 1.2645e-02, 2.8605e-05], grad_fn=<AddBackward0>)\n",
            "weights_43 tensor([4.6575e-01, 5.1493e-02, 1.1719e-05], grad_fn=<AddBackward0>)\n",
            "weights_44 tensor([4.6252e+00, 5.1054e-03, 5.1524e-05], grad_fn=<AddBackward0>)\n",
            "weights_45 tensor([0.3277, 0.0354, 0.0047], grad_fn=<AddBackward0>)\n",
            "weights_46 tensor([8.7189e+00, 2.4317e-03, 1.5998e-04], grad_fn=<AddBackward0>)\n",
            "weights_47 tensor([4.5046e+00, 4.9530e-03, 4.5389e-05], grad_fn=<AddBackward0>)\n",
            "weights_48 tensor([3.1774e+01, 6.3120e-04, 2.5739e-04], grad_fn=<AddBackward0>)\n",
            "weights_49 tensor([1.0813e+00, 1.9975e-02, 2.4597e-05], grad_fn=<AddBackward0>)\n",
            "weights_50 tensor([3.1799e+01, 6.0641e-04, 2.4728e-04], grad_fn=<AddBackward0>)\n",
            "weights_51 tensor([3.1811e+01, 5.9473e-04, 2.4252e-04], grad_fn=<AddBackward0>)\n",
            "weights_52 tensor([3.1820e+01, 5.8349e-04, 2.3793e-04], grad_fn=<AddBackward0>)\n",
            "weights_53 tensor([1.6872, 0.0096, 0.0054], grad_fn=<AddBackward0>)\n",
            "weights_54 tensor([1.3311e+00, 1.4209e-02, 1.6416e-05], grad_fn=<AddBackward0>)\n",
            "weights_55 tensor([3.1852e+01, 5.5218e-04, 2.2517e-04], grad_fn=<AddBackward0>)\n",
            "weights_56 tensor([4.6385e+00, 3.9405e-03, 3.9229e-05], grad_fn=<AddBackward0>)\n",
            "weights_57 tensor([7.8637e+00, 2.2367e-03, 8.4689e-05], grad_fn=<AddBackward0>)\n",
            "weights_58 tensor([3.1883e+01, 5.2407e-04, 2.1370e-04], grad_fn=<AddBackward0>)\n",
            "weights_59 tensor([3.1888e+01, 5.1531e-04, 2.1013e-04], grad_fn=<AddBackward0>)\n",
            "weights_60 tensor([3.1898e+01, 5.0686e-04, 2.0669e-04], grad_fn=<AddBackward0>)\n",
            "weights_61 tensor([3.1907e+01, 4.9867e-04, 2.0335e-04], grad_fn=<AddBackward0>)\n",
            "weights_62 tensor([3.1916e+01, 4.9075e-04, 2.0011e-04], grad_fn=<AddBackward0>)\n",
            "weights_63 tensor([7.2826e+00, 2.1259e-04, 9.0854e-04], grad_fn=<AddBackward0>)\n",
            "weights_64 tensor([3.1927e+01, 4.7562e-04, 1.9395e-04], grad_fn=<AddBackward0>)\n",
            "weights_65 tensor([3.1938e+01, 4.6841e-04, 1.9101e-04], grad_fn=<AddBackward0>)\n",
            "weights_66 tensor([6.5049e+00, 2.4315e-03, 4.9802e-05], grad_fn=<AddBackward0>)\n",
            "weights_67 tensor([2.5371e+00, 6.2906e-05, 2.7167e-03], grad_fn=<AddBackward0>)\n",
            "weights_68 tensor([3.1957e+01, 4.4802e-04, 1.8269e-04], grad_fn=<AddBackward0>)\n",
            "weights_69 tensor([5.1443e-01, 2.9309e-05, 1.3162e-02], grad_fn=<AddBackward0>)\n",
            "weights_70 tensor([1.1836e+00, 1.2407e-02, 1.0223e-05], grad_fn=<AddBackward0>)\n",
            "weights_71 tensor([6.6969e+00, 1.6509e-04, 8.8700e-04], grad_fn=<AddBackward0>)\n",
            "weights_72 tensor([3.1983e+01, 4.2344e-04, 1.7267e-04], grad_fn=<AddBackward0>)\n",
            "weights_73 tensor([2.3094e+00, 6.1080e-03, 2.1688e-05], grad_fn=<AddBackward0>)\n",
            "weights_74 tensor([3.1991e+01, 4.1213e-04, 1.6806e-04], grad_fn=<AddBackward0>)\n",
            "weights_75 tensor([4.9967e+00, 1.0165e-04, 1.1864e-03], grad_fn=<AddBackward0>)\n",
            "weights_76 tensor([3.2001e+01, 4.0141e-04, 1.6368e-04], grad_fn=<AddBackward0>)\n",
            "weights_77 tensor([3.2005e+01, 3.9626e-04, 1.6158e-04], grad_fn=<AddBackward0>)\n",
            "weights_78 tensor([3.2012e+01, 3.9123e-04, 1.5954e-04], grad_fn=<AddBackward0>)\n",
            "weights_79 tensor([4.1485e+00, 7.5202e-05, 1.4508e-03], grad_fn=<AddBackward0>)\n",
            "weights_80 tensor([3.2020e+01, 3.8156e-04, 1.5559e-04], grad_fn=<AddBackward0>)\n",
            "weights_81 tensor([3.2027e+01, 3.7690e-04, 1.5369e-04], grad_fn=<AddBackward0>)\n",
            "weights_82 tensor([3.2031e+01, 3.7236e-04, 1.5184e-04], grad_fn=<AddBackward0>)\n",
            "weights_83 tensor([3.2034e+01, 3.6792e-04, 1.5003e-04], grad_fn=<AddBackward0>)\n",
            "weights_84 tensor([3.2041e+01, 3.6360e-04, 1.4827e-04], grad_fn=<AddBackward0>)\n",
            "weights_85 tensor([3.2043e+01, 3.5936e-04, 1.4654e-04], grad_fn=<AddBackward0>)\n",
            "weights_86 tensor([3.2046e+01, 3.5522e-04, 1.4485e-04], grad_fn=<AddBackward0>)\n",
            "weights_87 tensor([3.2049e+01, 3.5117e-04, 1.4320e-04], grad_fn=<AddBackward0>)\n",
            "weights_88 tensor([7.9506e+00, 1.4146e-03, 7.2970e-05], grad_fn=<AddBackward0>)\n",
            "weights_89 tensor([6.7265e+00, 1.3810e-04, 6.9607e-04], grad_fn=<AddBackward0>)\n",
            "weights_90 tensor([2.5035e+00, 7.7766e-05, 2.1922e-03], grad_fn=<AddBackward0>)\n",
            "weights_91 tensor([3.2064e+01, 3.3589e-04, 1.3697e-04], grad_fn=<AddBackward0>)\n",
            "weights_92 tensor([3.2072e+01, 3.3229e-04, 1.3550e-04], grad_fn=<AddBackward0>)\n",
            "weights_93 tensor([3.2071e+01, 3.2874e-04, 1.3405e-04], grad_fn=<AddBackward0>)\n",
            "weights_94 tensor([3.8491e+00, 2.8348e-03, 2.2716e-05], grad_fn=<AddBackward0>)\n",
            "weights_95 tensor([3.2080e+01, 3.2189e-04, 1.3126e-04], grad_fn=<AddBackward0>)\n",
            "weights_96 tensor([2.7368e-01, 3.9154e-02, 6.7371e-06], grad_fn=<AddBackward0>)\n",
            "weights_97 tensor([3.2084e+01, 3.1530e-04, 1.2857e-04], grad_fn=<AddBackward0>)\n",
            "weights_98 tensor([3.2088e+01, 3.1212e-04, 1.2728e-04], grad_fn=<AddBackward0>)\n",
            "weights_99 tensor([3.2094e+01, 3.0901e-04, 1.2601e-04], grad_fn=<AddBackward0>)\n",
            "weights_100 tensor([3.2098e+01, 3.0594e-04, 1.2476e-04], grad_fn=<AddBackward0>)\n",
            "weights_101 tensor([3.6283e+00, 5.7499e-05, 1.2863e-03], grad_fn=<AddBackward0>)\n",
            "weights_102 tensor([3.2098e+01, 2.9998e-04, 1.2233e-04], grad_fn=<AddBackward0>)\n",
            "weights_103 tensor([3.2103e+01, 2.9710e-04, 1.2115e-04], grad_fn=<AddBackward0>)\n",
            "weights_104 tensor([3.2105e+01, 2.9426e-04, 1.1999e-04], grad_fn=<AddBackward0>)\n",
            "weights_105 tensor([3.2110e+01, 2.9149e-04, 1.1886e-04], grad_fn=<AddBackward0>)\n",
            "weights_106 tensor([3.2112e+01, 2.8876e-04, 1.1775e-04], grad_fn=<AddBackward0>)\n",
            "weights_107 tensor([3.2117e+01, 2.8609e-04, 1.1666e-04], grad_fn=<AddBackward0>)\n",
            "weights_108 tensor([3.2114e+01, 2.8346e-04, 1.1559e-04], grad_fn=<AddBackward0>)\n",
            "weights_109 tensor([3.2121e+01, 2.8088e-04, 1.1454e-04], grad_fn=<AddBackward0>)\n",
            "weights_110 tensor([3.2122e+01, 2.7834e-04, 1.1350e-04], grad_fn=<AddBackward0>)\n",
            "weights_111 tensor([3.2129e+01, 2.7587e-04, 1.1249e-04], grad_fn=<AddBackward0>)\n",
            "weights_112 tensor([3.2127e+01, 2.7342e-04, 1.1149e-04], grad_fn=<AddBackward0>)\n",
            "weights_113 tensor([3.2126e+01, 2.7101e-04, 1.1051e-04], grad_fn=<AddBackward0>)\n",
            "weights_114 tensor([3.2131e+01, 2.6866e-04, 1.0955e-04], grad_fn=<AddBackward0>)\n",
            "weights_115 tensor([6.8427e+00, 1.2700e-03, 4.1543e-05], grad_fn=<AddBackward0>)\n",
            "weights_116 tensor([2.2672e+00, 3.9874e-03, 1.8812e-05], grad_fn=<AddBackward0>)\n",
            "weights_117 tensor([3.2138e+01, 2.6182e-04, 1.0676e-04], grad_fn=<AddBackward0>)\n",
            "weights_118 tensor([3.2139e+01, 2.5961e-04, 1.0586e-04], grad_fn=<AddBackward0>)\n",
            "weights_119 tensor([3.2141e+01, 2.5745e-04, 1.0498e-04], grad_fn=<AddBackward0>)\n",
            "weights_120 tensor([3.1967e+01, 5.0917e-04, 1.0381e-04], grad_fn=<AddBackward0>)\n",
            "weights_121 tensor([3.1971e+01, 5.0500e-04, 1.0296e-04], grad_fn=<AddBackward0>)\n",
            "weights_122 tensor([6.6326e+00, 2.5477e-03, 3.3636e-05], grad_fn=<AddBackward0>)\n",
            "weights_123 tensor([6.6939e+00, 2.4518e-03, 2.7642e-05], grad_fn=<AddBackward0>)\n",
            "weights_124 tensor([3.1984e+01, 4.9291e-04, 1.0050e-04], grad_fn=<AddBackward0>)\n",
            "weights_125 tensor([5.5933e+00, 2.8506e-03, 2.4352e-05], grad_fn=<AddBackward0>)\n",
            "weights_126 tensor([3.1987e+01, 4.8516e-04, 9.8919e-05], grad_fn=<AddBackward0>)\n",
            "weights_127 tensor([3.1991e+01, 4.8138e-04, 9.8149e-05], grad_fn=<AddBackward0>)\n",
            "weights_128 tensor([2.7575e+00, 5.6848e-03, 1.2186e-05], grad_fn=<AddBackward0>)\n",
            "weights_129 tensor([4.5538e+00, 5.1201e-03, 1.8581e-05], grad_fn=<AddBackward0>)\n",
            "weights_130 tensor([2.0475e+00, 1.1274e-02, 7.5449e-06], grad_fn=<AddBackward0>)\n",
            "weights_131 tensor([3.1842e+01, 6.9835e-04, 9.4925e-05], grad_fn=<AddBackward0>)\n",
            "weights_132 tensor([1.7556e+00, 1.2880e-02, 7.3218e-06], grad_fn=<AddBackward0>)\n",
            "weights_133 tensor([3.1850e+01, 6.8798e-04, 9.3516e-05], grad_fn=<AddBackward0>)\n",
            "weights_134 tensor([1.8697e+00, 1.1856e-02, 1.1397e-05], grad_fn=<AddBackward0>)\n",
            "weights_135 tensor([3.1859e+01, 6.7791e-04, 9.2147e-05], grad_fn=<AddBackward0>)\n",
            "weights_136 tensor([3.1863e+01, 6.7299e-04, 9.1478e-05], grad_fn=<AddBackward0>)\n",
            "weights_137 tensor([1.6422e+00, 5.3223e-04, 1.9272e-03], grad_fn=<AddBackward0>)\n",
            "weights_138 tensor([3.1870e+01, 6.6334e-04, 9.0167e-05], grad_fn=<AddBackward0>)\n",
            "weights_139 tensor([3.1874e+01, 6.5862e-04, 8.9526e-05], grad_fn=<AddBackward0>)\n",
            "weights_140 tensor([3.1876e+01, 6.5397e-04, 8.8894e-05], grad_fn=<AddBackward0>)\n",
            "weights_141 tensor([3.1882e+01, 6.4939e-04, 8.8270e-05], grad_fn=<AddBackward0>)\n",
            "weights_142 tensor([2.1321e+00, 9.2915e-05, 1.6027e-03], grad_fn=<AddBackward0>)\n",
            "weights_143 tensor([1.2756e+00, 4.2529e-04, 1.0184e-03], grad_fn=<AddBackward0>)\n",
            "weights_144 tensor([3.1891e+01, 6.3601e-04, 8.6451e-05], grad_fn=<AddBackward0>)\n",
            "weights_145 tensor([3.1897e+01, 6.3167e-04, 8.5862e-05], grad_fn=<AddBackward0>)\n",
            "weights_146 tensor([3.1899e+01, 6.2739e-04, 8.5280e-05], grad_fn=<AddBackward0>)\n",
            "weights_147 tensor([3.1901e+01, 6.2317e-04, 8.4706e-05], grad_fn=<AddBackward0>)\n",
            "weights_148 tensor([8.3021e+00, 2.4036e-03, 3.6616e-05], grad_fn=<AddBackward0>)\n",
            "weights_149 tensor([3.1908e+01, 6.1490e-04, 8.3582e-05], grad_fn=<AddBackward0>)\n",
            "weights_150 tensor([3.1911e+01, 6.1083e-04, 8.3029e-05], grad_fn=<AddBackward0>)\n",
            "weights_151 tensor([3.1915e+01, 6.0684e-04, 8.2486e-05], grad_fn=<AddBackward0>)\n",
            "weights_152 tensor([3.1919e+01, 6.0290e-04, 8.1951e-05], grad_fn=<AddBackward0>)\n",
            "weights_153 tensor([3.1923e+01, 5.9900e-04, 8.1420e-05], grad_fn=<AddBackward0>)\n",
            "weights_154 tensor([3.1787e+01, 7.9171e-04, 8.0712e-05], grad_fn=<AddBackward0>)\n",
            "weights_155 tensor([3.1789e+01, 7.8665e-04, 8.0196e-05], grad_fn=<AddBackward0>)\n",
            "weights_156 tensor([3.1795e+01, 7.8168e-04, 7.9690e-05], grad_fn=<AddBackward0>)\n",
            "weights_157 tensor([2.9234e+00, 8.6454e-03, 1.7857e-05], grad_fn=<AddBackward0>)\n",
            "weights_158 tensor([1.1556e+00, 2.1702e-02, 5.5149e-06], grad_fn=<AddBackward0>)\n",
            "weights_159 tensor([8.3232e+00, 2.9878e-03, 2.7009e-05], grad_fn=<AddBackward0>)\n",
            "weights_160 tensor([3.1232e+00, 7.9305e-03, 1.0493e-05], grad_fn=<AddBackward0>)\n",
            "weights_161 tensor([3.1814e+01, 7.5770e-04, 7.7245e-05], grad_fn=<AddBackward0>)\n",
            "weights_162 tensor([3.1816e+01, 7.5308e-04, 7.6774e-05], grad_fn=<AddBackward0>)\n",
            "weights_163 tensor([3.1819e+01, 7.4850e-04, 7.6308e-05], grad_fn=<AddBackward0>)\n",
            "weights_164 tensor([5.6642e+00, 2.3888e-04, 4.9044e-04], grad_fn=<AddBackward0>)\n",
            "weights_165 tensor([8.9101e-01, 2.7058e-02, 5.9667e-06], grad_fn=<AddBackward0>)\n",
            "weights_166 tensor([3.1829e+01, 7.3514e-04, 7.4945e-05], grad_fn=<AddBackward0>)\n",
            "weights_167 tensor([1.5161e+00, 1.5700e-02, 5.1176e-06], grad_fn=<AddBackward0>)\n",
            "weights_168 tensor([3.1836e+01, 7.2650e-04, 7.4064e-05], grad_fn=<AddBackward0>)\n",
            "weights_169 tensor([3.1839e+01, 7.2225e-04, 7.3631e-05], grad_fn=<AddBackward0>)\n",
            "weights_170 tensor([3.1843e+01, 7.1806e-04, 7.3203e-05], grad_fn=<AddBackward0>)\n",
            "weights_171 tensor([2.3017e+00, 1.0038e-02, 9.1577e-06], grad_fn=<AddBackward0>)\n",
            "weights_172 tensor([6.3844e+00, 3.6504e-03, 2.1339e-05], grad_fn=<AddBackward0>)\n",
            "weights_173 tensor([3.1853e+01, 7.0574e-04, 7.1948e-05], grad_fn=<AddBackward0>)\n",
            "weights_174 tensor([8.6438e+00, 2.6044e-03, 3.4257e-05], grad_fn=<AddBackward0>)\n",
            "weights_175 tensor([3.1860e+01, 6.9777e-04, 7.1135e-05], grad_fn=<AddBackward0>)\n",
            "weights_176 tensor([4.0934e-01, 5.5416e-02, 1.1307e-05], grad_fn=<AddBackward0>)\n",
            "weights_177 tensor([8.3277e-01, 2.6872e-02, 3.9753e-06], grad_fn=<AddBackward0>)\n",
            "weights_178 tensor([2.2893e+00, 9.7306e-03, 1.1570e-05], grad_fn=<AddBackward0>)\n",
            "weights_179 tensor([1.3235e+00, 1.6669e-02, 4.1616e-06], grad_fn=<AddBackward0>)\n",
            "weights_180 tensor([7.6048e+00, 2.9333e-03, 2.2897e-05], grad_fn=<AddBackward0>)\n",
            "weights_181 tensor([3.1877e+01, 6.7488e-04, 6.8802e-05], grad_fn=<AddBackward0>)\n",
            "weights_182 tensor([3.1879e+01, 6.7121e-04, 6.8428e-05], grad_fn=<AddBackward0>)\n",
            "weights_183 tensor([2.7735e+00, 7.8051e-03, 1.5361e-05], grad_fn=<AddBackward0>)\n",
            "weights_184 tensor([3.1885e+01, 6.6399e-04, 6.7692e-05], grad_fn=<AddBackward0>)\n",
            "weights_185 tensor([5.7326e+00, 3.7260e-03, 1.6831e-05], grad_fn=<AddBackward0>)\n",
            "weights_186 tensor([3.1890e+01, 6.5694e-04, 6.6973e-05], grad_fn=<AddBackward0>)\n",
            "weights_187 tensor([4.1100e+00, 5.1673e-03, 1.2253e-05], grad_fn=<AddBackward0>)\n",
            "weights_188 tensor([5.0121e+00, 4.2588e-03, 1.6539e-05], grad_fn=<AddBackward0>)\n",
            "weights_189 tensor([3.1898e+01, 6.4661e-04, 6.5920e-05], grad_fn=<AddBackward0>)\n",
            "weights_190 tensor([3.1902e+01, 6.4326e-04, 6.5578e-05], grad_fn=<AddBackward0>)\n",
            "weights_191 tensor([1.5439e+00, 1.4127e-03, 5.8337e-04], grad_fn=<AddBackward0>)\n",
            "weights_192 tensor([7.4041e+00, 2.8045e-03, 1.8935e-05], grad_fn=<AddBackward0>)\n",
            "weights_193 tensor([3.1911e+01, 6.3335e-04, 6.4568e-05], grad_fn=<AddBackward0>)\n",
            "weights_194 tensor([3.1912e+01, 6.3012e-04, 6.4239e-05], grad_fn=<AddBackward0>)\n",
            "weights_195 tensor([3.1913e+01, 6.2692e-04, 6.3913e-05], grad_fn=<AddBackward0>)\n",
            "weights_196 tensor([3.1918e+01, 6.2376e-04, 6.3591e-05], grad_fn=<AddBackward0>)\n",
            "weights_197 tensor([3.1918e+01, 6.2062e-04, 6.3270e-05], grad_fn=<AddBackward0>)\n",
            "weights_198 tensor([1.4249e+00, 1.4091e-02, 3.6993e-06], grad_fn=<AddBackward0>)\n",
            "weights_199 tensor([3.1925e+01, 6.1445e-04, 6.2641e-05], grad_fn=<AddBackward0>)\n",
            "weights_200 tensor([3.1927e+01, 6.1141e-04, 6.2331e-05], grad_fn=<AddBackward0>)\n",
            "weights_201 tensor([3.1930e+01, 6.0840e-04, 6.2025e-05], grad_fn=<AddBackward0>)\n",
            "weights_202 tensor([3.1931e+01, 6.0541e-04, 6.1720e-05], grad_fn=<AddBackward0>)\n",
            "weights_203 tensor([3.2182e+00, 6.0686e-03, 9.7819e-06], grad_fn=<AddBackward0>)\n",
            "weights_204 tensor([3.1935e+01, 5.9953e-04, 6.1120e-05], grad_fn=<AddBackward0>)\n",
            "weights_205 tensor([3.1937e+01, 5.9663e-04, 6.0824e-05], grad_fn=<AddBackward0>)\n",
            "weights_206 tensor([3.1941e+01, 5.9377e-04, 6.0533e-05], grad_fn=<AddBackward0>)\n",
            "weights_207 tensor([5.2272e-01, 3.6670e-02, 1.8961e-06], grad_fn=<AddBackward0>)\n",
            "weights_208 tensor([5.2954e+00, 3.6128e-03, 1.2903e-05], grad_fn=<AddBackward0>)\n",
            "weights_209 tensor([3.1945e+01, 5.8531e-04, 5.9671e-05], grad_fn=<AddBackward0>)\n",
            "weights_210 tensor([3.1391e-01, 6.0350e-02, 2.5681e-06], grad_fn=<AddBackward0>)\n",
            "weights_211 tensor([3.1949e+01, 5.7981e-04, 5.9110e-05], grad_fn=<AddBackward0>)\n",
            "weights_212 tensor([3.1954e+01, 5.7711e-04, 5.8835e-05], grad_fn=<AddBackward0>)\n",
            "weights_213 tensor([3.1955e+01, 5.7443e-04, 5.8562e-05], grad_fn=<AddBackward0>)\n",
            "weights_214 tensor([3.1958e+01, 5.7178e-04, 5.8291e-05], grad_fn=<AddBackward0>)\n",
            "weights_215 tensor([3.1957e+01, 5.6912e-04, 5.8021e-05], grad_fn=<AddBackward0>)\n",
            "weights_216 tensor([4.5660e+00, 4.0591e-03, 1.3625e-05], grad_fn=<AddBackward0>)\n",
            "weights_217 tensor([3.1961e+01, 5.6393e-04, 5.7491e-05], grad_fn=<AddBackward0>)\n",
            "weights_218 tensor([6.9224e+00, 2.6565e-03, 1.6791e-05], grad_fn=<AddBackward0>)\n",
            "weights_219 tensor([3.1966e+01, 5.5882e-04, 5.6971e-05], grad_fn=<AddBackward0>)\n",
            "weights_220 tensor([3.1968e+01, 5.5631e-04, 5.6714e-05], grad_fn=<AddBackward0>)\n",
            "weights_221 tensor([4.6298e+00, 3.8451e-03, 1.8283e-05], grad_fn=<AddBackward0>)\n",
            "weights_222 tensor([8.4350e-01, 2.1239e-02, 3.5655e-06], grad_fn=<AddBackward0>)\n",
            "weights_223 tensor([3.1975e+01, 5.4889e-04, 5.5958e-05], grad_fn=<AddBackward0>)\n",
            "weights_224 tensor([3.1977e+01, 5.4646e-04, 5.5711e-05], grad_fn=<AddBackward0>)\n",
            "weights_225 tensor([3.1978e+01, 5.4407e-04, 5.5466e-05], grad_fn=<AddBackward0>)\n",
            "weights_226 tensor([3.1980e+01, 5.4167e-04, 5.5222e-05], grad_fn=<AddBackward0>)\n",
            "weights_227 tensor([3.1982e+01, 5.3931e-04, 5.4981e-05], grad_fn=<AddBackward0>)\n",
            "weights_228 tensor([6.8855e+00, 2.5375e-03, 1.5289e-05], grad_fn=<AddBackward0>)\n",
            "weights_229 tensor([3.1985e+01, 5.3464e-04, 5.4505e-05], grad_fn=<AddBackward0>)\n",
            "weights_230 tensor([1.0978e-02, 1.5758e+00, 3.1095e-06], grad_fn=<AddBackward0>)\n",
            "weights_231 tensor([3.1988e+01, 5.3005e-04, 5.4037e-05], grad_fn=<AddBackward0>)\n",
            "weights_232 tensor([3.1991e+01, 5.2778e-04, 5.3807e-05], grad_fn=<AddBackward0>)\n",
            "weights_233 tensor([3.1901e+01, 6.5593e-04, 5.3496e-05], grad_fn=<AddBackward0>)\n",
            "weights_234 tensor([3.1905e+01, 6.5316e-04, 5.3271e-05], grad_fn=<AddBackward0>)\n",
            "weights_235 tensor([1.4298e+00, 1.4724e-02, 3.8945e-06], grad_fn=<AddBackward0>)\n",
            "weights_236 tensor([3.1818e+01, 7.7604e-04, 5.2744e-05], grad_fn=<AddBackward0>)\n",
            "weights_237 tensor([8.8154e+00, 2.8048e-03, 2.4758e-05], grad_fn=<AddBackward0>)\n",
            "weights_238 tensor([3.1823e+01, 7.6959e-04, 5.2306e-05], grad_fn=<AddBackward0>)\n",
            "weights_239 tensor([3.1824e+01, 7.6640e-04, 5.2089e-05], grad_fn=<AddBackward0>)\n",
            "weights_240 tensor([3.1829e+01, 7.6326e-04, 5.1876e-05], grad_fn=<AddBackward0>)\n",
            "weights_241 tensor([3.1829e+01, 7.6012e-04, 5.1662e-05], grad_fn=<AddBackward0>)\n",
            "weights_242 tensor([3.1831e+01, 7.5700e-04, 5.1451e-05], grad_fn=<AddBackward0>)\n",
            "weights_243 tensor([3.6497e+00, 6.6915e-03, 7.5129e-06], grad_fn=<AddBackward0>)\n",
            "weights_244 tensor([3.1837e+01, 7.5088e-04, 5.1034e-05], grad_fn=<AddBackward0>)\n",
            "weights_245 tensor([2.8757e+00, 1.2031e-04, 8.3516e-04], grad_fn=<AddBackward0>)\n",
            "weights_246 tensor([3.1840e+01, 7.4484e-04, 5.0624e-05], grad_fn=<AddBackward0>)\n",
            "weights_247 tensor([3.1842e+01, 7.4184e-04, 5.0420e-05], grad_fn=<AddBackward0>)\n",
            "weights_248 tensor([3.1844e+01, 7.3889e-04, 5.0219e-05], grad_fn=<AddBackward0>)\n",
            "weights_249 tensor([8.3087e+00, 2.8503e-03, 1.8248e-05], grad_fn=<AddBackward0>)\n",
            "weights_250 tensor([3.1848e+01, 7.3303e-04, 4.9821e-05], grad_fn=<AddBackward0>)\n",
            "weights_251 tensor([7.8567e+00, 3.0133e-03, 1.5289e-05], grad_fn=<AddBackward0>)\n",
            "weights_252 tensor([6.5219e+00, 3.6224e-03, 1.4980e-05], grad_fn=<AddBackward0>)\n",
            "weights_253 tensor([3.1855e+01, 7.2443e-04, 4.9237e-05], grad_fn=<AddBackward0>)\n",
            "weights_254 tensor([1.7844e+00, 1.3075e-02, 4.6493e-06], grad_fn=<AddBackward0>)\n",
            "weights_255 tensor([1.0941e+00, 2.1145e-02, 2.0501e-06], grad_fn=<AddBackward0>)\n",
            "weights_256 tensor([3.1863e+01, 7.1605e-04, 4.8667e-05], grad_fn=<AddBackward0>)\n",
            "weights_257 tensor([3.1865e+01, 7.1329e-04, 4.8479e-05], grad_fn=<AddBackward0>)\n",
            "weights_258 tensor([3.1867e+01, 7.1055e-04, 4.8293e-05], grad_fn=<AddBackward0>)\n",
            "weights_259 tensor([3.1869e+01, 7.0783e-04, 4.8109e-05], grad_fn=<AddBackward0>)\n",
            "weights_260 tensor([4.0601e+00, 5.5876e-03, 1.3932e-05], grad_fn=<AddBackward0>)\n",
            "weights_261 tensor([6.3176e+00, 3.6000e-03, 1.1899e-05], grad_fn=<AddBackward0>)\n",
            "weights_262 tensor([3.1874e+01, 6.9981e-04, 4.7563e-05], grad_fn=<AddBackward0>)\n",
            "weights_263 tensor([2.7401e+00, 8.2122e-03, 5.1389e-06], grad_fn=<AddBackward0>)\n",
            "weights_264 tensor([3.1879e+01, 6.9456e-04, 4.7206e-05], grad_fn=<AddBackward0>)\n",
            "weights_265 tensor([3.1881e+01, 6.9198e-04, 4.7031e-05], grad_fn=<AddBackward0>)\n",
            "weights_266 tensor([3.5785e-01, 6.1999e-02, 1.4995e-06], grad_fn=<AddBackward0>)\n",
            "weights_267 tensor([3.1885e+01, 6.8684e-04, 4.6682e-05], grad_fn=<AddBackward0>)\n",
            "weights_268 tensor([5.2272e+00, 4.2352e-03, 1.0492e-05], grad_fn=<AddBackward0>)\n",
            "weights_269 tensor([3.1887e+01, 6.8178e-04, 4.6338e-05], grad_fn=<AddBackward0>)\n",
            "weights_270 tensor([7.7075e+00, 2.8481e-03, 1.4307e-05], grad_fn=<AddBackward0>)\n",
            "weights_271 tensor([1.6829e+00, 1.3073e-02, 1.4627e-05], grad_fn=<AddBackward0>)\n",
            "weights_272 tensor([1.2190e+00, 2.0743e-02, 3.5806e-06], grad_fn=<AddBackward0>)\n",
            "weights_273 tensor([3.1818e+01, 7.8286e-04, 4.5607e-05], grad_fn=<AddBackward0>)\n",
            "weights_274 tensor([3.1818e+01, 7.8002e-04, 4.5442e-05], grad_fn=<AddBackward0>)\n",
            "weights_275 tensor([3.1821e+01, 7.7721e-04, 4.5278e-05], grad_fn=<AddBackward0>)\n",
            "weights_276 tensor([2.8146e+00, 8.8695e-03, 5.1216e-06], grad_fn=<AddBackward0>)\n",
            "weights_277 tensor([4.6249e+00, 5.3924e-03, 9.1754e-06], grad_fn=<AddBackward0>)\n",
            "weights_278 tensor([3.1830e+01, 7.6894e-04, 4.4796e-05], grad_fn=<AddBackward0>)\n",
            "weights_279 tensor([8.7575e+00, 2.7999e-03, 1.9964e-05], grad_fn=<AddBackward0>)\n",
            "weights_280 tensor([3.1831e+01, 7.6349e-04, 4.4478e-05], grad_fn=<AddBackward0>)\n",
            "weights_281 tensor([3.1832e+01, 7.6080e-04, 4.4322e-05], grad_fn=<AddBackward0>)\n",
            "weights_282 tensor([3.1835e+01, 7.5814e-04, 4.4167e-05], grad_fn=<AddBackward0>)\n",
            "weights_283 tensor([1.7321e-01, 1.4028e-01, 1.4298e-06], grad_fn=<AddBackward0>)\n",
            "weights_284 tensor([8.9790e+00, 2.6703e-03, 4.1787e-05], grad_fn=<AddBackward0>)\n",
            "weights_285 tensor([3.1843e+01, 7.5025e-04, 4.3707e-05], grad_fn=<AddBackward0>)\n",
            "weights_286 tensor([3.1844e+01, 7.4764e-04, 4.3555e-05], grad_fn=<AddBackward0>)\n",
            "weights_287 tensor([8.2225e-01, 3.0627e-02, 2.6468e-04], grad_fn=<AddBackward0>)\n",
            "weights_288 tensor([9.7306e-01, 2.4603e-02, 3.1326e-06], grad_fn=<AddBackward0>)\n",
            "weights_289 tensor([8.9878e+00, 2.9963e-03, 2.2654e-05], grad_fn=<AddBackward0>)\n",
            "weights_290 tensor([3.2795e+00, 8.2236e-03, 6.2384e-06], grad_fn=<AddBackward0>)\n",
            "weights_291 tensor([8.3776e+00, 3.2329e-03, 1.4050e-05], grad_fn=<AddBackward0>)\n",
            "weights_292 tensor([3.1782e+01, 8.3607e-04, 4.2619e-05], grad_fn=<AddBackward0>)\n",
            "weights_293 tensor([3.1784e+01, 8.3324e-04, 4.2474e-05], grad_fn=<AddBackward0>)\n",
            "weights_294 tensor([3.2793e+00, 8.1503e-03, 7.6233e-06], grad_fn=<AddBackward0>)\n",
            "weights_295 tensor([2.0038e+00, 1.3364e-02, 6.4182e-06], grad_fn=<AddBackward0>)\n",
            "weights_296 tensor([3.1790e+01, 8.2489e-04, 4.2049e-05], grad_fn=<AddBackward0>)\n",
            "weights_297 tensor([4.2331e+00, 6.2484e-03, 6.4951e-06], grad_fn=<AddBackward0>)\n",
            "weights_298 tensor([3.1794e+01, 8.1943e-04, 4.1770e-05], grad_fn=<AddBackward0>)\n",
            "weights_299 tensor([8.5688e+00, 3.0593e-03, 1.5017e-05], grad_fn=<AddBackward0>)\n",
            "weights_300 tensor([3.0174e+00, 8.7162e-03, 7.7354e-06], grad_fn=<AddBackward0>)\n",
            "weights_301 tensor([3.1800e+01, 8.1135e-04, 4.1358e-05], grad_fn=<AddBackward0>)\n",
            "weights_302 tensor([3.1803e+01, 8.0869e-04, 4.1223e-05], grad_fn=<AddBackward0>)\n",
            "weights_303 tensor([3.9273e+00, 6.5409e-03, 2.1661e-05], grad_fn=<AddBackward0>)\n",
            "weights_304 tensor([5.5176e+00, 2.5707e-04, 2.7433e-04], grad_fn=<AddBackward0>)\n",
            "weights_305 tensor([8.2356e+00, 3.1327e-03, 1.3030e-05], grad_fn=<AddBackward0>)\n",
            "weights_306 tensor([3.1809e+01, 7.9823e-04, 4.0690e-05], grad_fn=<AddBackward0>)\n",
            "weights_307 tensor([3.1812e+01, 7.9566e-04, 4.0559e-05], grad_fn=<AddBackward0>)\n",
            "weights_308 tensor([3.1814e+01, 7.9311e-04, 4.0429e-05], grad_fn=<AddBackward0>)\n",
            "weights_309 tensor([3.3997e-02, 7.4640e-01, 1.7347e-06], grad_fn=<AddBackward0>)\n",
            "weights_310 tensor([5.8077e-01, 4.3654e-02, 3.9932e-06], grad_fn=<AddBackward0>)\n",
            "weights_311 tensor([3.1819e+01, 7.8554e-04, 4.0043e-05], grad_fn=<AddBackward0>)\n",
            "weights_312 tensor([7.8207e+00, 4.4891e-04, 1.6973e-04], grad_fn=<AddBackward0>)\n",
            "weights_313 tensor([3.1822e+01, 7.8057e-04, 3.9790e-05], grad_fn=<AddBackward0>)\n",
            "weights_314 tensor([1.0992e+00, 1.8955e-03, 1.0062e-03], grad_fn=<AddBackward0>)\n",
            "weights_315 tensor([3.1827e+01, 7.7568e-04, 3.9540e-05], grad_fn=<AddBackward0>)\n",
            "weights_316 tensor([3.1828e+01, 7.7325e-04, 3.9416e-05], grad_fn=<AddBackward0>)\n",
            "weights_317 tensor([3.1829e+01, 7.7083e-04, 3.9293e-05], grad_fn=<AddBackward0>)\n",
            "weights_318 tensor([4.4148e+00, 5.6300e-03, 8.2400e-06], grad_fn=<AddBackward0>)\n",
            "auto_alpha tensor(0.2500, grad_fn=<AddBackward0>)\n",
            "auto_lambda_0 tensor(79.5322, grad_fn=<AddBackward0>)\n",
            "auto_lambda_1 tensor(39.2993, grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_jO5rrUc_XY",
        "colab_type": "code",
        "outputId": "6f1698f3-1d30-4714-de0d-5a5948e337f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        }
      },
      "source": [
        "  # zi = pyro.sample(\"z\", dist.Categorical(torch.Tensor([1])))\n",
        "  # print (zi.item())\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-10-510bd1c62fef>\", line 12, in <module>\n",
            "    Y = mop(X)\n",
            "  File \"<ipython-input-10-510bd1c62fef>\", line 9, in mop\n",
            "    return sum( [weights[i] * poisson.pmf(X, rate[i]) for i in range(10)] )\n",
            "  File \"<ipython-input-10-510bd1c62fef>\", line 9, in <listcomp>\n",
            "    return sum( [weights[i] * poisson.pmf(X, rate[i]) for i in range(10)] )\n",
            "NameError: name 'rate' is not defined\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 725, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.6/inspect.py\", line 709, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.6/posixpath.py\", line 383, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7awLENdusJz",
        "colab_type": "code",
        "outputId": "30ff208a-d294-4ba6-b234-c41ebaf5c129",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        }
      },
      "source": [
        "print(pyro.get_param_store())\n",
        "\n",
        "from scipy.stats import poisson\n",
        "\n",
        "X = np.arange(0, 300)\n",
        "\n",
        "print (pyro.param('weights_318').detach().numpy())\n",
        "# print ([pyro.param('auto_lambda_{}'.format(i)).detach().item() for i in range(10)])\n",
        "\n",
        "def mop(X):\n",
        "  weights = pyro.param('weights_318').detach().numpy()\n",
        "  rates = [pyro.param('auto_lambda_{}'.format(i)).detach().item() for i in range(10)]\n",
        "  return sum( [weights[i] * poisson.pmf(X, rates[i]) for i in range(10)] )\n",
        "\n",
        "\n",
        "Y = mop(X)\n",
        "# print(Y)\n",
        "plt.hist(data, bins=40, density=True, lw=0, alpha=0.75);\n",
        "plt.plot(X, Y)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<pyro.params.param_store.ParamStoreDict object at 0x7f4b1c7d3cc0>\n",
            "[1.5012006e-01 1.3002673e-01 8.6913568e-01 5.8970086e-02 8.6771660e-03\n",
            " 3.3982229e-05 1.6991236e-05 8.4957028e-06 6.0944916e-03 1.6991236e-05\n",
            " 4.5757077e-04]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w/JR/eRVgKcrwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}